{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e369909c-da83-4d18-a331-a235534528af",
   "metadata": {},
   "source": [
    "# validator2\n",
    "\n",
    "This notebook validates materials citations annotation using Darwin core archives downloaded from GGI server. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07124511-12af-4f3b-a87b-f005e6c6f912",
   "metadata": {},
   "source": [
    "### old docs - delete eventually\n",
    "\n",
    "This notebook controls execution of GGI using **pyautogui**.\n",
    "\n",
    "It was written to automate downloading XML files for documents from Insects of Guam I and II\n",
    "as part of a validation process.\n",
    "\n",
    "This is a fragile hack which probably runs only on my particular setup.\n",
    "\n",
    "Run in Jupyter lab using the Python 3 kernel. \n",
    "\n",
    "The JupyterLab window should display on my laptop, with GGI displaying on the \"big screen\" (2560 x 1080)\n",
    "\n",
    "Remember to push to GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8a8cdd5-ccf1-4804-9434-1c3bafb0a9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pyautogui as pag\n",
    "import time\n",
    "#import mysecrets\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "#from bs4 import BeautifulSoup\n",
    "import re\n",
    "#import json\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27e1808f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset_list():\n",
    "    '''\n",
    "    Reads ../dataset-list.md and returns a pandas dataframe\n",
    "    '''\n",
    "    \n",
    "    # Read a markdown file, getting the header from the first row and inex from the second column\n",
    "    # df = pd.read_table('../dataset-list.md', sep=\"|\", header=0, index_col=1, skipinitialspace=True)\n",
    "    \n",
    "    df = pd.read_table('../dataset-list.md', sep=\"|\", header=0, skipinitialspace=True)\n",
    "\n",
    "    # Drop the left-most and right-most null columns \n",
    "    \n",
    "    df = df.dropna(axis=1, how='all')\n",
    "\n",
    "    # Drop the header underline row\n",
    "    \n",
    "    df = df.iloc[1:]  \n",
    "\n",
    "    # Left-align strings and column headings\n",
    "    # df = df.style.set_properties(**{'text-align': 'left'})\n",
    "    # df = df.set_table_styles([dict(selector = 'th', props=[('text-align', 'left')])])\n",
    "\n",
    "    # Strip whitespace from end of strings\n",
    "    \n",
    "    df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "    # Strip whitespace from end of column headers\n",
    "    \n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    # Drop datasets with no title - we don't need to process these\n",
    "    \n",
    "    df = df.drop(df[df.title == 'no title'].index)\n",
    "    return df\n",
    "\n",
    "# read_dataset_list()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5586fc51-e93b-4c4b-83a2-58aabc55442a",
   "metadata": {},
   "source": [
    "XMLDIR = '/home/aubrey/Desktop/data-mining-insects-of-guam/MatCit-Validator'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a9f03d33-634e-4e13-8b68-caec3c255c55",
   "metadata": {},
   "source": [
    "pag.PAUSE = 5"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6b46d8a1-8776-4259-bb1c-db8b554f0191",
   "metadata": {
    "tags": []
   },
   "source": [
    "def open_GGI():\n",
    "    pag.hotkey('ctrl','alt','t')\n",
    "    pag.typewrite('cd GGI\\n')\n",
    "    pag.typewrite('java -jar GgImagineStarter.jar\\n')\n",
    "    pag.typewrite('\\n')\n",
    "    time.sleep(10)\n",
    "\n",
    "    pag.click(1141, 565, duration=2) # select configuration\n",
    "    pag.click(1469, 646, duration=2) # click configuration button\n",
    "    pag.click(1590, 562, duration=2) # look and feel\n",
    "    pag.click(1259, 635, duration=2) # select JAVA\n",
    "    pag.click(1267, 709, duration=2) # OK\n",
    "    pag.click(1143, 648, duration=2) # OK\n",
    "    pag.click(1766, 171, duration=2) # maximize window"
   ]
  },
  {
   "cell_type": "raw",
   "id": "651087df-1451-4873-a427-31c4b4f9d0a6",
   "metadata": {},
   "source": [
    "def login():\n",
    "    '''\n",
    "    This function spoofs a login by clicking on File | Load from GGI server items on the main GGI menu.\n",
    "    The first time that a download is requested during a session results in a login dialog.\n",
    "    \n",
    "    My username is remembered by GGI, so this function provides only my password. Note that I keep \n",
    "    this private by reading it from mysecrets.py which is included in .gitignore. The pertinant line looks like\n",
    "    \"password = <my GGI password>\".\n",
    "    \n",
    "    This function does not download a document from the GGI server, but exits after pressing the \"cancel\" button.    \n",
    "    '''\n",
    "    pag.click(  92,  69, duration=2) # File\n",
    "    pag.click( 122, 134, duration=2) # load from GGI server\n",
    "    pag.press('enter')\n",
    "    pag.typewrite(mysecrets.password)  # password\n",
    "    pag.press('enter')\n",
    "    pag.click(1371, 594, duration=2) # cancel"
   ]
  },
  {
   "cell_type": "raw",
   "id": "92b3d44c-6a82-43bd-ad3b-81db7c21dec2",
   "metadata": {},
   "source": [
    "def load_doc(uuid):\n",
    "    pag.click(  92,  69, duration=2) # File\n",
    "    pag.click( 122, 134, duration=2) # load from GGI server\n",
    "    pag.typewrite(uuid)\n",
    "    pag.press('enter')\n",
    "    \n",
    "# load_doc('FF86FFC39D5F6775A307302F3260421D')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cdd1a1cb-bfa6-4c16-801d-726504f576c5",
   "metadata": {},
   "source": [
    "def export_xml(uuid):\n",
    "    pag.click(133,  72, duration=2) # Export\n",
    "    pag.click(151, 154, duration=2) # Export XML\n",
    "    xml_path = f'{XMLDIR}/{uuid}'\n",
    "    pag.press('backspace')          # Remove space character in textbox\n",
    "    pag.typewrite(xml_path)\n",
    "    pag.press('enter')\n",
    "    \n",
    "# export_xml('FF86FFC39D5F6775A307302F3260421D')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "54a05521-ed86-4a60-a188-a3d02e51b758",
   "metadata": {},
   "source": [
    "def close_doc():\n",
    "    pag.click(  92,  69, duration=2) # File\n",
    "    pag.click( 132, 214, duration=2) # Close Document\n",
    "\n",
    "# close_doc()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a819b243-0c2e-40b6-9531-aa36e7f6258d",
   "metadata": {},
   "source": [
    "def process_doc(uuid):\n",
    "    cl = f'papermill -p UUID {uuid} MatCit-Validator.ipynb {uuid}.ipynb'\n",
    "    x = subprocess.run(cl, shell=True, capture_output=True, text=True)\n",
    "    if x.returncode != 0:\n",
    "        print(x.stderr)\n",
    "        \n",
    "# process_doc('FF86FFC39D5F6775A307302F3260421D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aea1a8e-d747-47e7-ac51-76e1ed614349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 6.44 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def update_github():\n",
    "    x = subprocess.run('git --git-dir=/home/aubrey/Desktop/data-mining-insects-of-guam/.git pull', \n",
    "                       shell=True, capture_output=True, text=True)\n",
    "    assert x.returncode==0, 'git pull failed'\n",
    "\n",
    "    x = subprocess.run('git --git-dir=/home/aubrey/Desktop/data-mining-insects-of-guam/.git add .', \n",
    "                       shell=True, capture_output=True, text=True)\n",
    "    assert x.returncode==0, 'git add . failed'\n",
    "        \n",
    "    x = subprocess.run('git  --git-dir=/home/aubrey/Desktop/data-mining-insects-of-guam/.git commit -m \"validator2\"', \n",
    "                       shell=True, capture_output=True, text=True)\n",
    "    assert x.returncode==0, 'git commit failed'\n",
    "        \n",
    "    x = subprocess.run('git --git-dir=/home/aubrey/Desktop/data-mining-insects-of-guam/.git push', \n",
    "                       shell=True, capture_output=True, text=True)\n",
    "    assert x.returncode==0, 'git push failed'\n",
    "\n",
    "# update_github()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b4c15abe-36ed-4e66-8b9b-f6bdb580120a",
   "metadata": {},
   "source": [
    "def nth_repl(s, sub, repl, n):\n",
    "    find = s.find(sub)\n",
    "    # If find is not -1 we have found at least one match for the substring\n",
    "    i = find != -1\n",
    "    # loop util we find the nth or we find no match\n",
    "    while find != -1 and i != n:\n",
    "        # find + 1 means we start searching from after the last match\n",
    "        find = s.find(sub, find + 1)\n",
    "        i += 1\n",
    "    # If i is equal to n we found nth match so replace\n",
    "    if i == n:\n",
    "        return s[:find] + repl + s[find+len(sub):]\n",
    "    return s\n",
    "\n",
    "# s = '''\n",
    "# <tr>\n",
    "#     <td>alpha</td>\n",
    "# </tr>\n",
    "# <tr>\n",
    "#     <td>beta</td>\n",
    "# </tr>\n",
    "# <tr>\n",
    "#     <td>cappa</td>\n",
    "# </tr>\n",
    "# '''\n",
    "# print(s)\n",
    "# print()\n",
    "# s = nth_repl(s, '<tr', '<tr caca', 2)\n",
    "# print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba951050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_status_report():\n",
    "        \n",
    "    summary_list = []\n",
    "    for uuid in uuids:\n",
    "        summary = json.load(open(f'{uuid}_summary.json'))\n",
    "        summary['uuid'] = uuid\n",
    "        summary_list.append(summary)\n",
    "    df_summary = pd.DataFrame(summary_list)\n",
    "    df_merged = pd.merge(df, df_summary, on='uuid')\n",
    "    df_merged.drop('status', axis=1, inplace=True)\n",
    "    #df_merged['validation report'] = f'<a href=\"{df_merged.uuid}.html\">validation report</a>'\n",
    "    summary_html = df_merged.to_html(index=False)\n",
    "    \n",
    "    # Edit so that the table is nicely styled with Bulma\n",
    "    \n",
    "    summary_html = summary_html.replace('<table border=\"1\" class=\"dataframe\">', '<table class=\"table\">')\n",
    "    summary_html = summary_html.replace('<th>', '<th class=\"has-text-centered\">')\n",
    "    summary_html = summary_html.replace('<td>', '<td class=\"has-text-centered\">')\n",
    "    \n",
    "    # Link uuid to validation report\n",
    "    \n",
    "    for uuid in uuids:\n",
    "        summary_html = summary_html.replace(uuid, f'<a href=\"{uuid}.html\">{uuid}</a>')\n",
    "    \n",
    "    # Highlight rows which need work\n",
    "    \n",
    "    for i, r in df_merged.iterrows():\n",
    "        if (r['bad collectors'] + r['bad locations'] + r['bad dates']) > 0:\n",
    "            summary_html = nth_repl(summary_html, '<tr', '<tr class=\"is-selected\"', i+2)  \n",
    "    \n",
    "    title_html = f'''\n",
    "        <p class=\"title is-1\">Insects of Guam Datamining Project</p>\n",
    "        <p class=\"subtitle is-3\">Status report generated by <b>validator2.ipynb</b> at {datetime.utcnow()} UTC</p>\n",
    "        <p>Highlited documents failed validation. Click on the **uuid** to see the validation report.</p>\n",
    "        '''\n",
    "\n",
    "    html = f'''\n",
    "        <html>\n",
    "            <header>\n",
    "                <meta charset=\"utf-8\">\n",
    "                <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
    "                <title>mat_cit_chk</title>\n",
    "                <link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/bulma@0.9.3/css/bulma.min.css\">\n",
    "            </header>\n",
    "            <body>\n",
    "                <section class=\"section\">\n",
    "                    <div class=\"container\">\n",
    "                        {title_html}\n",
    "                        {summary_html}\n",
    "                    </div>\n",
    "                </section>\n",
    "            </body>\n",
    "        </html>        \n",
    "        '''\n",
    "    with open('status_report.html', 'w') as f:\n",
    "        f.write(html) \n",
    "        \n",
    "# create_status_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "487b821d-7042-4dcb-95fe-1047eee21227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.05 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def get_dwca(uuid):\n",
    "    \"\"\"\n",
    "    Downloads a Darwin core archive from the GGI server, unzips it, and creates a pandas dataframe\n",
    "    for selected tables. \n",
    "    \"\"\"\n",
    "    dwca_url = f'http://tb.plazi.org/GgServer/dwca/{uuid}.zip'\n",
    "    dwca_file = f'{uuid}.zip'\n",
    "\n",
    "    # download the DwCA into the current working directory, \n",
    "    # overwriting any previous DwCA with same uuid\n",
    "\n",
    "    command = f'wget -O {dwca_file} {dwca_url}'\n",
    "    result = os.system(command)\n",
    "    assert result==0, f'{command} failed'\n",
    "\n",
    "    # unzip the DwCA, overwriting files:\n",
    "    #   meta.xml, eml.xml, taxa.txt, occurrences.txt, multimedia.txt, description.txt, distribution.txt, \n",
    "    #   media.txt, references.txt, vernaculars.txt\n",
    "\n",
    "    command = f'unzip -o {dwca_file}'\n",
    "    result = os.system(command)\n",
    "    assert result==0, f'{command} failed'  \n",
    "\n",
    "    command = f'unzip -o {dwca_file}'\n",
    "    result = os.system(command)\n",
    "    assert result==0, f'{command} failed'  \n",
    "\n",
    "# get_dwca('FE566D11FFD2FFF5383F9056FFE3FFEF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cb6655f-e04b-4853-94c2-92814f769b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.05 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def validate_dwca():\n",
    "    taxon_df = pd.read_csv('taxa.txt', sep='\\t')\n",
    "    occ_df = pd.read_csv('occurrences.txt', sep='\\t') \n",
    "    occ_df.eventDate = occ_df.eventDate.astype(str)\n",
    "\n",
    "    merged_df = taxon_df.merge(right=occ_df, on='taxonID')\n",
    "    assert merged_df.shape[0]==occ_df.shape[0],'merged_df does not have same number of records as occ_df'\n",
    "    \n",
    "    merged_df = merged_df[['canonicalName','country','locality','recordedBy','eventDate']]\n",
    "    \n",
    "    print(merged_df.dtypes)\n",
    "    \n",
    "    date_list = ['1936']\n",
    "    merged_df['valid_eventDate'] = merged_df['eventDate'].str[:4].isin(date_list)\n",
    "    \n",
    "    author_list = ['O. H. Swezey', 'R. L. Usinger & O. H.Swezey']\n",
    "    merged_df['valid_recordedBy'] = merged_df['recordedBy'].isin(author_list)\n",
    "    \n",
    "    locality_list = ['Sumay Road', 'Tarague Beach', 'Machanoa', 'Orote Peninsula']\n",
    "    merged_df['valid_locality'] = merged_df['locality'].isin(author_list)\n",
    "    \n",
    "    country_list = ['Guam']\n",
    "    merged_df['valid_country'] = merged_df['locality'].isin(country_list)\n",
    "        \n",
    "    return merged_df\n",
    "            \n",
    "# validate_dwca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a3047a8-876c-4d6a-844f-ae7c2dcb8a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating\n",
      "FFF07216FFA41642FFBAFFE7FFCA482A\n",
      "canonicalName    object\n",
      "country          object\n",
      "locality         object\n",
      "recordedBy       object\n",
      "eventDate        object\n",
      "dtype: object\n",
      "A676FD1EF22D3F34FF8F8907FFDAFC58\n",
      "canonicalName     object\n",
      "country          float64\n",
      "locality          object\n",
      "recordedBy        object\n",
      "eventDate         object\n",
      "dtype: object\n",
      "FF8CA776FF947F25FF920C4AFFF5FF0F\n",
      "canonicalName     object\n",
      "country          float64\n",
      "locality          object\n",
      "recordedBy        object\n",
      "eventDate         object\n",
      "dtype: object\n",
      "FFDEFF89B713A955FFD59822FF8CFF82\n",
      "canonicalName     object\n",
      "country          float64\n",
      "locality          object\n",
      "recordedBy        object\n",
      "eventDate         object\n",
      "dtype: object\n",
      "6137FFB29C68FFD2FFB6585FFF92FFC4\n",
      "canonicalName    object\n",
      "country          object\n",
      "locality         object\n",
      "recordedBy       object\n",
      "eventDate        object\n",
      "dtype: object\n",
      "Creating status report\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-b5ce33928577>\u001b[0m in \u001b[0;36mcreate_status_report\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msummary_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0muuid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muuids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{uuid}_summary.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0msummary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'uuid'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muuid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0msummary_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# MAIN\n",
    "\n",
    "df = read_dataset_list()\n",
    "\n",
    "# lets process the first 15 datasets\n",
    "\n",
    "# open_GGI()\n",
    "# login()\n",
    "\n",
    "# Validate each DwCA\n",
    "\n",
    "print('Validating')\n",
    "\n",
    "uuids = list(df.iloc[0:5].uuid.values)\n",
    "for uuid in uuids:\n",
    "    print(uuid)\n",
    "    get_dwca(uuid)\n",
    "    validate_dwca()\n",
    "\n",
    "print('Creating status report')\n",
    "\n",
    "create_status_report()\n",
    "\n",
    "print('Updating GitHub')\n",
    "\n",
    "update_github()\n",
    "        \n",
    "print('FINISHED')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
