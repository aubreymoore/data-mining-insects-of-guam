{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e369909c-da83-4d18-a331-a235534528af",
   "metadata": {},
   "source": [
    "# validator2\n",
    "\n",
    "This notebook validates materials citations annotation using Darwin core archives downloaded from GGI server. \n",
    "\n",
    "If my laptop is online, this Jupyter notebook will run during the second minute of every hour under this crontab entry:\n",
    "```\n",
    "2 * * * * ~/Desktop/data-mining-insects-of-guam/validator2/run_validator2.sh >~/Desktop/data-mining-insects-of-guam/validator2/run_validator2.log 2>&1\n",
    "```\n",
    "\n",
    "The bash file (run_validator2.sh) runs the notebook using **papermill**:\n",
    "```\n",
    "#!/bin/bash\n",
    "cd ~/Desktop/data-mining-insects-of-guam/validator2/\n",
    "/home/aubrey/.local/bin/papermill validator2.ipynb output.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8a8cdd5-ccf1-4804-9434-1c3bafb0a9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import re\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1733c09-0403-4e2f-9320-a172269c0563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This list is currently maintained \"manually\".\n",
    "\n",
    "author_list = [\n",
    "    'A. Cruz',\n",
    "    'E. H. Bryan',\n",
    "    'E. H. Bryan and O. H. Swezey',\n",
    "    'T. E. Esaki',\n",
    "    'D. T. Fullaway',\n",
    "    'H. G. Hornbostel',\n",
    "    'R. G. Oakley',\n",
    "    'Z. Ono',\n",
    "    'O. H. Swezey',\n",
    "    'O. H. Swezey and R. L. Usinger',\n",
    "    'Rowley',\n",
    "    'R. L. Usinger',\n",
    "    'R. L. Usinger and O. H. Swezey',\n",
    "    'unknown',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cf07bac-6abf-4c76-9c88-ea55e945a70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This list is currently maintained \"manually\".\n",
    "\n",
    "locality_list = [\n",
    "    'Agana',\n",
    "    'Agana Swamp',\n",
    "    'Agat',\n",
    "    'Agfayan',\n",
    "    'Asan',\n",
    "    'Atao Beach',\n",
    "    'Barrigada',\n",
    "    'Dandan',\n",
    "    'Dededo',\n",
    "    'Fadian',\n",
    "    'Government House, Agana',\n",
    "    'Guam',\n",
    "    'Inarajan',\n",
    "    'Machanao',\n",
    "    'Mata',\n",
    "    'Merizo',\n",
    "    'Mogfog',\n",
    "    'Mt. Alifan',\n",
    "    'Mount Alifan',\n",
    "    'Mount Chachao',\n",
    "    'Mt. Sasalaguan',\n",
    "    'Mount Sasalaguan', \n",
    "    'Mount Tenjo',\n",
    "    'Orote Peninsula',\n",
    "    'Orote Point',\n",
    "    'Passan',\n",
    "    'Piti',\n",
    "    'Ritidian Point',\n",
    "    'Rota Island',\n",
    "    'Root School Farm',\n",
    "    'Santa Rosa Peak',\n",
    "    'Sumay Road',\n",
    "    'Tarague',\n",
    "    'Tarague Beach',\n",
    "    'Tumon',\n",
    "    'Umatac',\n",
    "    'Upi Trail',\n",
    "    'Yigo',\n",
    "    'Yona',\n",
    "    'Atantano',\n",
    "    'Talofofo',\n",
    "    'Libugon Farm',\n",
    "    'Sumay',\n",
    "    'Fonte Valley',\n",
    "    'Ponape',\n",
    "    'Ponape, Mount Nanalaut',\n",
    "    'Ponape, Nipit-Ninoani',\n",
    "    'Ponape, Kolonia-Nat',\n",
    "    'Babelthaup, Marukyoku',\n",
    "    'Kusaie, Mount Wakapp',\n",
    "    'Tiyan',\n",
    "    'Libugon',\n",
    "    'Palae',\n",
    "    'Magua',\n",
    "    'Saipan'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd7e3470-06be-4855-9c2b-93906e48c8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list = [\n",
    "    '1911',\n",
    "    '1925',\n",
    "    '1936',\n",
    "    '1937',\n",
    "    '1938',\n",
    "    '1939',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b562a34e-a316-4b6e-a20d-45fd7d9f2f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_list = [\n",
    "    'Guam',\n",
    "    'Northern Mariana Islands',\n",
    "    'Palau',\n",
    "    'Micronesia (Federated States of)',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27e1808f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset_list():\n",
    "    '''\n",
    "    Reads ../dataset-list.md and returns a pandas dataframe\n",
    "    '''\n",
    "    \n",
    "    df = pd.read_table('../dataset-list.md', sep=\"|\", header=0, skipinitialspace=True)\n",
    "\n",
    "    # Drop the left-most and right-most null columns \n",
    "    \n",
    "    df = df.dropna(axis=1, how='all')\n",
    "\n",
    "    # Drop the header underline row\n",
    "    \n",
    "    df = df.iloc[1:]  \n",
    "\n",
    "    # Strip whitespace from end of strings\n",
    "    \n",
    "    df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "    # Strip whitespace from end of column headers\n",
    "    \n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    # Drop datasets with no title - we don't need to process these\n",
    "    \n",
    "    df = df.drop(df[df.title == 'no title'].index)\n",
    "    return df\n",
    "\n",
    "# read_dataset_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4aea1a8e-d747-47e7-ac51-76e1ed614349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 4.53 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def update_github():\n",
    "    command = f'./update_github.sh'\n",
    "    result = os.system(command)\n",
    "    assert result==0, f'{command} failed'  \n",
    "\n",
    "# update_github()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fafd107b-6ec8-4235-b03d-a4ff05d21f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datestamp():\n",
    "    df = pd.read_xml('eml.xml', xpath=\".//additionalMetadata/metadata/gbif\")\n",
    "    return df.dateStamp[0]\n",
    "\n",
    "# get_datestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cb6655f-e04b-4853-94c2-92814f769b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.77 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def validate_dwca(uuid):\n",
    "    \"\"\"\n",
    "    Downloads a Darwin core archive from the GGI server, unzips it. \n",
    "    \n",
    "    Summary saved to <uuid>.html\n",
    "    \"\"\"\n",
    "    dwca_url = f'http://tb.plazi.org/GgServer/dwca/{uuid}.zip'\n",
    "    dwca_file = f'{uuid}.zip'\n",
    "\n",
    "    # download the DwCA into the current working directory, \n",
    "    # overwriting any previous DwCA with same uuid\n",
    "\n",
    "    command = f'wget -O {dwca_file} {dwca_url}'\n",
    "    result = os.system(command)\n",
    "    assert result==0, f'{command} failed'\n",
    "\n",
    "    # unzip the DwCA, overwriting files:  \n",
    "    #   meta.xml, eml.xml, taxa.txt, occurrences.txt, multimedia.txt, description.txt, distribution.txt, \n",
    "    #   media.txt, references.txt, vernaculars.txt\n",
    "\n",
    "    command = f'unzip -o {dwca_file}'\n",
    "    result = os.system(command)\n",
    "    assert result==0, f'{command} failed'  \n",
    "    \n",
    "    # delete zip file\n",
    "\n",
    "    command = f'rm {dwca_file}'\n",
    "    result = os.system(command)\n",
    "    assert result==0, f'{command} failed'  \n",
    "       \n",
    "    taxon_df = pd.read_csv('taxa.txt', sep='\\t')\n",
    "    occ_df = pd.read_csv('occurrences.txt', sep='\\t') \n",
    "    occ_df.eventDate = occ_df.eventDate.astype(str)\n",
    "\n",
    "    merged_df = taxon_df.merge(right=occ_df, on='taxonID')\n",
    "    assert merged_df.shape[0]==occ_df.shape[0],'merged_df does not have same number of records as occ_df'\n",
    "    \n",
    "    merged_df = merged_df[['canonicalName','country','locality','recordedBy','eventDate']]\n",
    "    \n",
    "    merged_df['valid_eventDate'] = merged_df['eventDate'].str[:4].isin(date_list)\n",
    "    merged_df['valid_recordedBy'] = merged_df['recordedBy'].isin(author_list)\n",
    "    merged_df['valid_locality'] = merged_df['locality'].isin(locality_list)\n",
    "    merged_df['valid_country'] = merged_df['country'].isin(country_list)\n",
    "\n",
    "    # title_html\n",
    "    \n",
    "    s = '<p class=\"title is-1\">Insects of Guam Datamining Project</p>\\n'\n",
    "    title = df[df[\"uuid\"]==uuid][\"title\"].to_list()[0]\n",
    "    s += f'<p class=\"subtitle is-3\">{title}</p>\\n'\n",
    "    s += f'<p><b>Darwin Core Archive:</b> <a href=\"{dwca_url}\">{dwca_url}</a></p>\\n'\n",
    "    s += f'<p>Generated by <b>validator2.ipynb</b> at {datetime.utcnow()} UTC</p>\\n'\n",
    "    title_html = s\n",
    "    \n",
    "    # results_html\n",
    "    \n",
    "    s = '<table class=\"table\">\\n'\n",
    "    s += '<thead>\\n'\n",
    "    s += '<tr>\\n'\n",
    "    s += '<th>canonicalName</th>\\n'\n",
    "    s += '<th>country</th>\\n'\n",
    "    s += '<th>locality</th>\\n'\n",
    "    s += '<th>recordedBy</th>\\n'\n",
    "    s += '<th>eventDate</th>\\n'\n",
    "    s += '</tr>\\n'\n",
    "    s += '</thead>\\n'\n",
    "    \n",
    "    for i,r in merged_df.iterrows():\n",
    "        s += '<tr>\\n'\n",
    "        s += f'<td><i>{r.canonicalName}</i></td>\\n'\n",
    "        \n",
    "        if r.valid_country:\n",
    "            s += f'<td>{r.country}</td>\\n'\n",
    "        else:\n",
    "            s += f'<td class=\"is-selected\">{r.country}</td>\\n'\n",
    "            \n",
    "        if r.valid_locality:\n",
    "            s += f'<td>{r.locality}</td>\\n'\n",
    "        else:\n",
    "            s += f'<td class=\"is-selected\">{r.locality}</td>\\n'\n",
    "                        \n",
    "        if r.valid_recordedBy:\n",
    "            s += f'<td>{r.recordedBy}</td>\\n'\n",
    "        else:\n",
    "            s += f'<td class=\"is-selected\">{r.recordedBy}</td>\\n'\n",
    "            \n",
    "        if r.valid_eventDate:\n",
    "            s += f'<td>{r.eventDate}</td>\\n'\n",
    "        else:\n",
    "            s += f'<td class=\"is-selected\">{r.eventDate}</td>\\n'\n",
    "            \n",
    "        s += '</tr>\\n'\n",
    "    s += '</table>\\n'\n",
    "    results_html = s\n",
    "    \n",
    "    # summary_html\n",
    "\n",
    "    summary_dict = {}\n",
    "    summary_dict['title'] = title\n",
    "    summary_dict['uuid'] = uuid\n",
    "    summary_dict['n_materials_citations'] = merged_df.shape[0]\n",
    "    summary_dict['n_treatments'] = len(pd.unique(merged_df['canonicalName']))    \n",
    "    summary_dict['n_invalid_country'] = merged_df[merged_df['valid_country']==False].shape[0]\n",
    "    summary_dict['n_invalid_locality'] = merged_df[merged_df['valid_locality']==False].shape[0]\n",
    "    summary_dict['n_invalid_recordedBy'] = merged_df[merged_df['valid_recordedBy']==False].shape[0]\n",
    "    summary_dict['n_invalid_eventDate'] = merged_df[merged_df['valid_eventDate']==False].shape[0]\n",
    "    summary_dict['datestamp'] = get_datestamp()\n",
    "    print(summary_dict)\n",
    "\n",
    "    s = '<table class=\"table\">\\n'\n",
    "    s += '<thead>\\n'\n",
    "    s += '<tr>\\n'\n",
    "    s += '<th>treatments</th>\\n'\n",
    "    s += '<th>materials_citations</th>\\n'\n",
    "    s += '<th>invalid_country</th>\\n'\n",
    "    s += '<th>invalid_locality</th>\\n'\n",
    "    s += '<th>invalid_recordedBy</th>\\n'\n",
    "    s += '<th>invalid_eventDate</th>\\n'\n",
    "    s += '<th>datestamp</th>\\n'\n",
    "    s += '</tr>\\n'\n",
    "    s += '</thead>\\n'\n",
    "    s += '<tr>\\n'\n",
    "    s += f'<td>{summary_dict[\"n_treatments\"]}</td>\\n'    \n",
    "    s += f'<td>{summary_dict[\"n_materials_citations\"]}</td>\\n'    \n",
    "    \n",
    "    for x in ['n_invalid_country', 'n_invalid_locality', 'n_invalid_recordedBy', 'n_invalid_eventDate', 'datestamp']:\n",
    "        if summary_dict[x] == 0:\n",
    "            s += f'<td>{summary_dict[x]}</td>\\n'\n",
    "        else:\n",
    "            s += f'<td class=\"is-selected\">{summary_dict[x]}</td>\\n'\n",
    "       \n",
    "    s += '</tr>\\n'\n",
    "    s += '</table>'\n",
    "   \n",
    "    summary_html = s\n",
    "       \n",
    "    # Write the validation report\n",
    "    \n",
    "    timestamp = datetime.utcnow()\n",
    "    html = f'''\n",
    "        <html>\n",
    "            <header>\n",
    "                <meta charset=\"utf-8\">\n",
    "                <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
    "                <title>validator2</title>\n",
    "                <link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/bulma@0.9.3/css/bulma.min.css\">\n",
    "            </header>\n",
    "            <body>\n",
    "                <section class=\"section\">\n",
    "                    <div class=\"container\">\n",
    "                        {title_html}\n",
    "                        {summary_html}\n",
    "                        {results_html}\n",
    "                    </div>\n",
    "                </section>\n",
    "            </body>\n",
    "        </html>        \n",
    "        '''\n",
    "    with open(f'{uuid}.html', 'w') as f:\n",
    "        f.write(html)        \n",
    "            \n",
    "    return summary_dict\n",
    "\n",
    "# validate_dwca('FE566D11FFD2FFF5383F9056FFE3FFEF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c64d240a-1d9c-4e47-aad6-c9b55e83cac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 5.01 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def generate_status_report(summary_list):\n",
    "    \n",
    "    # controlled_vocabularie_html\n",
    "\n",
    "    s = '<p class=\"title is-3\">Controlled vocabularies\\n'\n",
    "\n",
    "    s += '<p class=\"title is-4\">Country</p>\\n'\n",
    "    for i in sorted(country_list):\n",
    "        s += f'<p>{i}</p>\\n'\n",
    "    s += '<br><br>'\n",
    "\n",
    "    s += '<p class=\"title is-4\">Locality</p>\\n'\n",
    "    for i in sorted(locality_list):\n",
    "        s += f'<p>{i}</p>\\n'\n",
    "    s += '<br><br>'\n",
    "\n",
    "    s += '<p class=\"title is-4\">recordedBy</p>\\n'\n",
    "    for i in sorted(author_list):\n",
    "        s += f'<p>{i}</p>\\n'\n",
    "    s += '<br><br>'\n",
    "\n",
    "    s += '<p class=\"title is-4\">eventDate (valid years)</p>\\n'\n",
    "    for i in sorted(date_list):\n",
    "        s += f'<p>{i}</p>\\n'\n",
    "    s += '<br><br>'\n",
    "        \n",
    "    controlled_vocabularies_html = s\n",
    "\n",
    "    # title_html\n",
    "\n",
    "    s = '<p class=\"title is-1\">Insects of Guam Datamining Project</p>\\n'\n",
    "    s += f'<p class=\"subtitle is-3\">Status report</p>\\n'\n",
    "    s += f'<p>Generated by <b>validator2.ipynb</b> at {datetime.utcnow()} UTC</p>'\n",
    "    s += '<p>Data are check against controlled vocabularies listed at the bottom of this report. Currently, these lists are maintained within <b>validator2.ipynb</b></p>\\n'\n",
    "    s += '<p>Click on a <b>uuid</b> to see validation results for the corresponding chapter.</p>'\n",
    "    title_html = s\n",
    "\n",
    "    # table_html\n",
    "\n",
    "    s = '<table class=\"table\">\\n'\n",
    "    s += '<thead>\\n'\n",
    "    s += '<tr>\\n'\n",
    "    s += '<th>uuid</th>\\n'\n",
    "    s += '<th>title</th>\\n'\n",
    "    s += '<th>treatments</th>\\n'\n",
    "    s += '<th>materials_citations</th>\\n'\n",
    "    s += '<th>invalid_country</th>\\n'\n",
    "    s += '<th>invalid_locality</th>\\n'\n",
    "    s += '<th>invalid_recordedBy</th>\\n'\n",
    "    s += '<th>invalid_eventDate</th>\\n'\n",
    "    s += '</tr>\\n'\n",
    "    s += '</thead>\\n'\n",
    "\n",
    "    for d in summary_list:\n",
    "        uuid = d['uuid']\n",
    "        s += '<tr>\\n'\n",
    "        s += f'<td><a href=\"{uuid}.html\">{uuid}</td>\\n' # link to validation report for this uuid\n",
    "        s += f'<td>{d[\"title\"]}</td>\\n'\n",
    "        s += f'<td>{d[\"n_treatments\"]}</td>\\n'    \n",
    "        s += f'<td>{d[\"n_materials_citations\"]}</td>\\n'    \n",
    "\n",
    "        for x in ['n_invalid_country', 'n_invalid_locality', 'n_invalid_recordedBy', 'n_invalid_eventDate']:\n",
    "            if d[x] == 0:\n",
    "                s += f'<td>{d[x]}</td>\\n'\n",
    "            else:\n",
    "                s += f'<td class=\"is-selected\">{d[x]}</td>\\n'\n",
    "\n",
    "        s += '</tr>\\n'\n",
    "    s += '</table>'\n",
    "    table_html = s\n",
    "\n",
    "    # Write the validation report\n",
    "\n",
    "    timestamp = datetime.utcnow()\n",
    "    html = f'''\n",
    "        <html>\n",
    "            <header>\n",
    "                <meta charset=\"utf-8\">\n",
    "                <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
    "                <title>validator2</title>\n",
    "                <link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/bulma@0.9.3/css/bulma.min.css\">\n",
    "            </header>\n",
    "            <body>\n",
    "                <section class=\"section\">\n",
    "                    <div class=\"container\">\n",
    "                        {title_html}\n",
    "                        {table_html}\n",
    "                        {controlled_vocabularies_html}\n",
    "                    </div>\n",
    "                </section>\n",
    "            </body>\n",
    "        </html>        \n",
    "        '''\n",
    "    with open(f'status_report.html', 'w') as f:\n",
    "        f.write(html)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe987296-5243-46cf-9067-6ec9e6289d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup():\n",
    "    files = ['meta.xml', 'eml.xml', 'taxa.txt', 'occurrences.txt', 'multimedia.txt', 'description.txt', 'distribution.txt', 'media.txt', 'references.txt', 'vernaculars.txt']\n",
    "    for f in files:\n",
    "        if os.path.exists(f):\n",
    "            os.remove(f)\n",
    "            \n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3047a8-876c-4d6a-844f-ae7c2dcb8a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating\n",
      "{'title': 'Strepsiptera of Guam', 'uuid': 'FFF07216FFA41642FFBAFFE7FFCA482A', 'n_materials_citations': 2, 'n_treatments': 1, 'n_invalid_country': 0, 'n_invalid_locality': 0, 'n_invalid_recordedBy': 0, 'n_invalid_eventDate': 0, 'datestamp': '2022-07-10T07:33:36+0000'}\n",
      "{'title': 'Halictine Bees from Rota Island', 'uuid': 'A676FD1EF22D3F34FF8F8907FFDAFC58', 'n_materials_citations': 3, 'n_treatments': 3, 'n_invalid_country': 0, 'n_invalid_locality': 0, 'n_invalid_recordedBy': 0, 'n_invalid_eventDate': 0, 'datestamp': '2022-05-03T23:10:30+0000'}\n",
      "{'title': 'Aphididae and Aleurodidae Of Guam', 'uuid': 'FF8CA776FF947F25FF920C4AFFF5FF0F', 'n_materials_citations': 9, 'n_treatments': 4, 'n_invalid_country': 0, 'n_invalid_locality': 0, 'n_invalid_recordedBy': 0, 'n_invalid_eventDate': 0, 'datestamp': '2022-07-10T06:41:44+0000'}\n",
      "{'title': 'Isoptera of Guam', 'uuid': 'FFDEFF89B713A955FFD59822FF8CFF82', 'n_materials_citations': 6, 'n_treatments': 3, 'n_invalid_country': 0, 'n_invalid_locality': 0, 'n_invalid_recordedBy': 0, 'n_invalid_eventDate': 0, 'datestamp': '2022-07-10T07:24:49+0000'}\n",
      "{'title': 'Ciidae of Guam', 'uuid': '6137FFB29C68FFD2FFB6585FFF92FFC4', 'n_materials_citations': 5, 'n_treatments': 4, 'n_invalid_country': 0, 'n_invalid_locality': 0, 'n_invalid_recordedBy': 0, 'n_invalid_eventDate': 0, 'datestamp': '2022-05-03T23:36:49+0000'}\n",
      "{'title': 'Sphingidae Of Guam', 'uuid': 'C5751610FFAD3E7CE078FFB1FFCFFF82', 'n_materials_citations': 15, 'n_treatments': 5, 'n_invalid_country': 0, 'n_invalid_locality': 0, 'n_invalid_recordedBy': 0, 'n_invalid_eventDate': 0, 'datestamp': '2022-07-09T10:57:26+0000'}\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# MAIN\n",
    "\n",
    "df = read_dataset_list()\n",
    "\n",
    "# Validate each DwCA\n",
    "\n",
    "print('Validating')\n",
    "\n",
    "summary_list = []\n",
    "\n",
    "uuids = list(df.uuid.values)\n",
    "for uuid in uuids:\n",
    "    summary_dict = validate_dwca(uuid)\n",
    "    summary_list.append(summary_dict)\n",
    "\n",
    "print('Generating status report')  \n",
    "generate_status_report(summary_list)\n",
    "\n",
    "print('Cleaning up')\n",
    "cleanup()\n",
    "\n",
    "print('Updating GitHub')\n",
    "update_github()\n",
    "        \n",
    "print('FINISHED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06052c16-ab4d-4c4f-a168-cb8248750d91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
