{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cba9028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31333493",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_XML_FILE = 'example.xml'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331d8481",
   "metadata": {},
   "source": [
    "## Fields from the Materials Citations Dialog\n",
    "\n",
    "```\n",
    "collectionCode, specimenCount, specimenCode, accessionNumber\n",
    "typestatus, collectingCountry, collectingRegion, collectingMunicipality\n",
    "collectingCounty, location, locationDeviation, originalDetermination\n",
    "determinerName, collectorName, collectingDate, collectedFrom\n",
    "collectingMethod, collectingPermit, geoCoordinate, elevation\n",
    "geologicalTimeScale, backReference\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defafa11",
   "metadata": {},
   "source": [
    "## Mapping Material Citation Fields to DwCA\n",
    "\n",
    "The following list was extracted from the DwCA meta.xml file. Here, we can see how GGI terms are mapped to DwCA terms.\n",
    "\n",
    "dwca | GGI|\n",
    "-----|:---|\n",
    "http://rs.tdwg.org/dwc/terms/taxonID|treatment ID + \".taxon\"\n",
    "http://rs.tdwg.org/dwc/terms/catalogNumber|mc@specimenCode (explode to one record per specimen code if possible)\n",
    "http://rs.tdwg.org/dwc/terms/collectionCode|mc@collectionCode (explode to one record per collection code if possible)\n",
    "http://rs.tdwg.org/dwc/terms/institutionCode|blank\n",
    "http://rs.tdwg.org/dwc/terms/typeStatus|mc@typeStatus (blank if none given)\n",
    "http://rs.gbif.org/terms/1.0/verbatimLabel|mc text\n",
    "http://rs.tdwg.org/dwc/terms/sex|mc@sex (also other specimen types like \"queen\", \"worker\", etc.)\n",
    "http://rs.tdwg.org/dwc/terms/individualCount|mc@specimenCount (explode things like \"5 workers, 2 females\" to one record per typified specimen count if possible)\n",
    "http://rs.tdwg.org/dwc/terms/eventDate|mc@collectingDate\n",
    "http://rs.tdwg.org/dwc/terms/recordedBy|mc@collectorName\n",
    "http://rs.tdwg.org/dwc/terms/recordNumber|blank\n",
    "http://rs.tdwg.org/dwc/terms/decimalLatitude|mc@latitude\n",
    "http://rs.tdwg.org/dwc/terms/decimalLongitude|mc@longitude\n",
    "http://rs.tdwg.org/dwc/terms/minimumElevationInMeters|mc@elevation, or mc@elevationMin if given\n",
    "http://rs.tdwg.org/dwc/terms/maximumElevationInMeters|mc@elevationMax if given\n",
    "http://rs.tdwg.org/dwc/terms/country|mc@collectingCountry\n",
    "http://rs.tdwg.org/dwc/terms/stateProvince|mc@stateProvince or mc@collectingRegion\n",
    "http://rs.tdwg.org/dwc/terms/municipality|mc@collectingMunicipality\n",
    "http://rs.tdwg.org/dwc/terms/locality|mc@location\n",
    "\n",
    "Here's my idea of which fields are required:\n",
    "\n",
    "* collectingDate\n",
    "* collectorName\n",
    "* collectingCountry\n",
    "* collectingMunicipality OR location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10ba1deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_cit_attr_fields = [\n",
    "    'specimenCode','collectionCode','typeStatus',\n",
    "    'sex','specimenCount','collectingDate',\n",
    "    'collectorName','latitude','longitude',\n",
    "    'elevation','elevationMin','elevationMax',\n",
    "    'collectingCountry','stateProvince','collectingMunicipality',\n",
    "    'location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b7e23ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_cit_child_fields = [\n",
    "    'collectionCode', 'specimenCount', 'specimenCode', 'accessionNumber',\n",
    "    'typestatus', 'collectingCountry', 'collectingRegion', 'collectingMunicipality',\n",
    "    'collectingCounty', 'location', 'locationDeviation', 'originalDetermination',\n",
    "    'determinerName', 'collectorName', 'collectingDate', 'collectedFrom',\n",
    "    'collectingMethod', 'collectingPermit', 'geoCoordinate', 'elevation',\n",
    "    'geologicalTimeScale', 'backReference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f949cb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "collector_list = ['O.H. Swezey', 'E. H. Bryan', 'R. L. Usinger']\n",
    "\n",
    "place_list = ['Ritidian Point','Agana','Barrigada','Piti']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cddcd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_required_fields(matcit):\n",
    "    html = ''\n",
    "#     if matcit.get('collectingdate','') == '':\n",
    "#         html += '<div class=\"notification is-danger\">ERROR: no collectiondate</div>\\n'\n",
    "    if matcit.get('collectorname','') == '':\n",
    "        html += '<div class=\"notification is-danger\">ERROR: no collectorname</div>\\n'\n",
    "    if matcit.get('collectingcountry','') == '':\n",
    "        html += '<div class=\"notification is-danger\">ERROR: no collectingcountry</div>\\n'\n",
    "    if (matcit.get('collectingmunicipality','') == '') and (matcit.get('location','') == ''):\n",
    "        html += '<div class=\"notification is-danger\">ERROR: no collectingmunicipality or location</div>\\n'\n",
    "    return html \n",
    "\n",
    "def check_for_unlisted_child_fields(matcit):\n",
    "    html =''\n",
    "    soup = BeautifulSoup(str(matcit))\n",
    "    li = soup.find('materialscitation')\n",
    "    children = li.findChildren(recursive=False)\n",
    "    for child in children:\n",
    "        if not (child.name in [x.lower() for x in mat_cit_child_fields]):\n",
    "            html += '<div class=\"notification is-info\">'\n",
    "            html += f'INFO: <b>{child.name}</b> is not a regular material citations child field'\n",
    "            html += '</div>\\n'\n",
    "    return html\n",
    "\n",
    "def check_for_unlisted_attribites(matcit):\n",
    "    html =''\n",
    "    for attr in matcit.attrs:\n",
    "        if not (attr in [x.lower() for x in mat_cit_attr_fields]):\n",
    "            html += '<div class=\"notification is-info\">'\n",
    "            html += f'INFO: <b>{attr}</b> is not a regular material citations attribute'\n",
    "            html += '</div>\\n'\n",
    "    return html\n",
    "\n",
    "def check_date(matcit, doc_attrs):\n",
    "    collectingdate = matcit.get('collectingdate','')\n",
    "    if collectingdate=='':\n",
    "        return '<div class=\"notification is-danger\">ERROR: no collectingdate</div>\\n' \n",
    "    matches = re.search('(\\d{4})', collectingdate)\n",
    "    if not matches:\n",
    "        return ''\n",
    "    year = matches.group(1)\n",
    "    if year > doc_attrs.get('docdate',''):\n",
    "        return '<div class=\"notification is-danger\">ERROR: collectingdate year is greater than publication date</div>\\n'    \n",
    "    return ''\n",
    "\n",
    "def check_location(matcit):\n",
    "    return ''\n",
    "\n",
    "def check_collector(matcit):\n",
    "    return ''\n",
    "\n",
    "def check_material_citation(matcit, doc_attrs):\n",
    "    html = ''\n",
    "#     html += check_required_fields(matcit)\n",
    "    html += check_date(matcit, doc_attrs)\n",
    "    html += check_location(matcit)\n",
    "    html += check_collector(matcit)\n",
    "    html += check_for_unlisted_attribites(matcit)\n",
    "    html += check_for_unlisted_child_fields(matcit)\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b432a34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_material_citations():\n",
    "    \n",
    "    # Read xml file into a string\n",
    "    \n",
    "    with open(PATH_TO_XML_FILE, 'r') as f:\n",
    "            s = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(s, 'lxml')\n",
    "\n",
    "    # List document attributes\n",
    "\n",
    "    doc_attrs = soup.find('document').attrs\n",
    "    html = f'<p class=\"title is-1\">{doc_attrs[\"doctitle\"]}</p>\\n'\n",
    "    html += f'<p class=\"subtitle is-3\">uuid: {doc_attrs[\"docid\"]}</p>\\n'\n",
    "    html += f'<p class=\"subtitle is-3\">Report generated by MatCit-Validator at {datetime.utcnow()} UTC</p>\\n'\n",
    "    html += f'<hr>\\n'\n",
    "    html += f'<p class=\"title is-2\">Document attributes</p>\\n'\n",
    "\n",
    "    for key in doc_attrs:\n",
    "        html += f'<b>{key}:</b> {doc_attrs[key]}<br>\\n'\n",
    "    html += '<hr>'\n",
    "\n",
    "    # Check material citations\n",
    "    \n",
    "    treatments = soup.find_all('treatment')\n",
    "    for treatment in treatments:\n",
    "        extract = treatment.text.split()[:4]\n",
    "        extract = ' '.join(extract)\n",
    "        html += f'<p class=\"title is-2\">treatment: {extract} ...</h1>\\n'\n",
    "\n",
    "        materialcitations = treatment.find_all('materialscitation')\n",
    "        for materialcitation in materialcitations:\n",
    "            html += f'<div class=\"notification is-info is-light\">{materialcitation.text}</div>\\n'\n",
    "            html += '<p class=\"title is-6\">Attributes</p>\\n'\n",
    "            for key in materialcitation.attrs:\n",
    "                html += f'<b>{key}:</b> {materialcitation[key]}<br>\\n'\n",
    "            html += '<br>\\n'\n",
    "            html += '<p class=\"title is-6\">Child nodes</p>\\n'\n",
    "            for child in materialcitation.findChildren(recursive=False):\n",
    "                html += f'<b>{child.name}:</b> {child.text}<br>'            \n",
    "            \n",
    "            html += check_material_citation(materialcitation, doc_attrs)\n",
    "            html += '<br><br><hr>\\n'\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c9a7666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_html_report(mat_cit_chk_html, output_file):\n",
    "    timestamp = datetime.utcnow()\n",
    "    html = f'''\n",
    "        <html>\n",
    "            <header>\n",
    "                <meta charset=\"utf-8\">\n",
    "                <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
    "                <title>mat_cit_chk</title>\n",
    "                <link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/bulma@0.9.3/css/bulma.min.css\">\n",
    "            </header>\n",
    "            <body>\n",
    "                <section class=\"section\">\n",
    "                    <div class=\"container\">\n",
    "                        {mat_cit_chk_html}\n",
    "                    </div>\n",
    "                </section>\n",
    "            </body>\n",
    "        </html>        \n",
    "        '''\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(html)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8d8f740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "\n",
    "mat_cit_chk_html = check_material_citations()\n",
    "generate_html_report(mat_cit_chk_html, PATH_TO_XML_FILE.replace('.xml','.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc3147d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
